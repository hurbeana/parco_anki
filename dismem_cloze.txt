The best possible communication network in terms of {{c1::diameter}} and {{c1::bisection width}} is the {{c2::fully connected network}}.;distributed_memory_systems network diameter bisection_width
The significant drawbacks of the fully connected network is {{c1::the large (maximum) number of links (\|V|(|V|−1)\)}} and {{c2::the high degree \((G)=|V|−1\)}}.;distributed_memory_systems network degree
The worst possible communication networks that can support parallel computing are the {{c1::linear processor array (single path/line of processor nodes)}} and the {{c2::processor ring (single cycle spanning all processor nodes)}}. (also tree structures);distributed_memory_systems network
Some factors that entail concrete, physical costs (space and money) when building a parallel computing system are {{c1::the number of communication edges and node degrees}} but also the {{c2::lengths of cables}}.;distributed_memory_systems network communication costs
A tree network is {{c1::minimal connected}} and therefore has a bisection width (bisec(T)) of {{c2::1}}.;distributed_memory_systems network graph bisection_width
A uniform (symmetric, homogeneous) mesh or torus network has the same order for all dimensions, that is: {{c1::\(r = \sqrt[d]{p}\)}}.;distributed_memory_systems network order
The bisection width of a symmetric mesh is bisec(M) = {{c1::\(p \frac{d-1}{d} = \frac{p}{r}\} }} and of a symmetric torus bisec(T) = {{c2::\(2p \frac{d-1}{d} = \frac{2p}{r}\} }}.;distributed_memory_systems network graph bisection_width
A hypercube network is a special case of a uniform torus (or mesh) network in which all coordinates are either \(x_i = 0 or x_i = 1\). The diameter, the degree and the dimension of a hypercube network are \(diam(H) = degree(H) = d = {{c1::log_2 p}}\) and the bisection width is \(bisec(H) = {{c2::\frac{p}{2} }}\).;distributed_memory_systems network hypercube diameter degree dimension bisection_width
Indirect networks with multiple switches of small, fully-connected networks are often called {{c1::multi-stage networks}}.;distributed_memory_systems network inderect_network
We say that a communication system is {{c1::one-ported (or single-ported)}} if a processor can engage in at most {{c2::one communication operation}} in a step.;distributed_memory_systems network communication
A communication system where a processor can be involved in up to k communication operations in the same step (that is, concurrently) is called {{c1::k-ported (or just multi-ported)}}.distributed_memory_systems network communication
Systems with indirect, multi-stage communication networks are often {{c1::one-ported}}.;distributed_memory_systems network inderect_network
Torus-based systems are most often {{2d-ported}} and can (roughly) support communication with all torus neighbors in a step.;distributed_memory_systems network torus
For the analysis of communication algorithms, we count the {{c1::total number of steps}} in which processors are communicating (until the last processor finishes). (Sometimes, such steps are called rounds.);distributed_memory_systems network communicating